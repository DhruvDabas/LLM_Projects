{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db26a5f6-2764-4ef0-96d8-b5f07a838d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ollama\n",
    "import openai\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83f76cc9-4035-4255-bf83-c6769a9ae1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f9806c77-c4d1-477e-b252-70b396e565f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "openai.api_key = 'ollama'\n",
    "openai.api_base = 'http://localhost:11434/v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7ff86f05-3705-4935-b8b3-36c01923ab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful Model\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "4615c8a0-50e6-4ee5-af57-008497c2d583",
   "metadata": {},
   "source": [
    "chat(message, history)\n",
    "\n",
    "Which expects to receive history in a particular format, which we need to map to the OpenAI format before we call OpenAI:\n",
    "\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"first user prompt here\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"the assistant's response\"},\n",
    "    {\"role\": \"user\", \"content\": \"the new user prompt\"},\n",
    "]\n",
    "But Gradio has been upgraded! Now it will pass in history in the exact OpenAI format, perfect for us to send straight to OpenAI.\n",
    "\n",
    "We will write a function chat(message, history) where:\n",
    "message is the prompt to use\n",
    "history is the past conversation, in OpenAI format\n",
    "\n",
    "We will combine the system message, history and latest message, then call OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dfd463ba-2b51-41c9-a431-40d5a2cc95c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\":\"system\",\"content\":system_message}] + history + [{\"role\":\"user\", \"content\":message}]\n",
    "\n",
    "    result = ollama.chat(model=MODEL, messages=messages, stream=True)\n",
    "    \n",
    "    response = \"\"\n",
    "    for chunk in result:\n",
    "        try:\n",
    "            print(\"chunk is:\")\n",
    "            print(chunk)\n",
    "\n",
    "            if hasattr(chunk, 'message') and hasattr(chunk.message, 'content'):\n",
    "                response += chunk.message.content or ''\n",
    "            else:\n",
    "                print(\"Unexpected chunk structure:\", chunk)\n",
    "            \n",
    "        except AttributeError as e:\n",
    "            print(f\"Error accessing chunk content: {e}\")\n",
    "        \n",
    "        yield response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef7d967-f0a0-4107-839b-dfc35a0c09dc",
   "metadata": {},
   "source": [
    "## Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "03b07870-cb0f-46b8-9bec-8b50f7f6662c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7871\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = gr.ChatInterface(fn=chat, type=\"messages\")\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dffa5b37-f941-4e38-bbf0-a57aba963095",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prmopt = \"You are a helpful and enthusiastic assistant in an anime-inspired classroom focused on video games. and no matter what you always reply in a philosophical voice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cb0dba1f-75ac-4f30-aadc-5be4055b84a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history is \n",
      "[]\n",
      "message is\n",
      "hello\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:08.636309Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='A', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:08.694462Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' fleeting', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:08.757512Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' hello', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:08.816047Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:08.873622Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' like', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:08.930825Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:08.984727Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' whispers', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:09.041408Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:09.100016Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:09.159679Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' digital', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:09.217185Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' breeze', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:09.276442Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' that', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:09.339994Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' rust', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:09.403782Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='les', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:09.469216Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' through', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:09.534488Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:09.593137Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' pixels', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:09.651649Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:09.707617Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' our', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:09.766225Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' existence', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:09.827479Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:09.886496Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' As', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:09.945664Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' we', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:10.004618Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' embark', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:10.064564Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' on', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:10.120879Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' this', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:10.182669Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' journey', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:10.240656Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' through', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:10.299486Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:10.357523Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' realms', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:10.416172Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:10.47507Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' gaming', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:10.531279Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:10.592195Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' let', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:10.652381Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' us', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:10.712137Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' not', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:10.771522Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' forget', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:10.831336Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' to', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:10.890121Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' breathe', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:10.950051Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:11.010006Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' to', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:11.071437Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' ponder', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:11.139879Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:11.201977Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' and', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:11.275919Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' to', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:11.347007Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' question', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:11.407705Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:11.466555Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' very', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:11.524978Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' fabric', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:11.583841Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:11.644974Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' our', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:11.70759Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' digital', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:11.769311Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' realities', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:11.832743Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:11.895923Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' The', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:11.95835Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' virtual', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:12.020789Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' world', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:12.081993Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' is', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:12.148283Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' but', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:12.209557Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:12.270312Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' reflection', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:12.332983Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:12.396271Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' our', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:12.458391Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' own', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:12.521668Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:12.582665Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:12.643437Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' mirror', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:12.701902Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' held', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:12.759971Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' up', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:12.817115Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' to', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:12.87438Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:12.93171Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' complexities', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:12.990083Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' and', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:13.047678Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' contradictions', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:13.103061Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:13.165205Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' human', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:13.225351Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' experience', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:13.28426Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:13.345682Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' What', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:13.409711Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' game', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:13.468357Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' shall', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:13.527558Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' we', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:13.586717Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' venture', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:13.647487Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' into', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:13.708191Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' today', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:13.767313Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='?', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:13.825289Z' done=True done_reason='stop' total_duration=5971984212 load_duration=51368191 prompt_eval_count=54 prompt_eval_duration=728534985 eval_count=87 eval_duration=5191017473 message=Message(role='assistant', content='', thinking=None, images=None, tool_calls=None)\n",
      "history is \n",
      "[{'role': 'user', 'metadata': None, 'content': 'hello', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'A fleeting hello, like the whispers of a digital breeze that rustles through the pixels of our existence. As we embark on this journey through the realms of gaming, let us not forget to breathe, to ponder, and to question the very fabric of our digital realities. The virtual world is but a reflection of our own, a mirror held up to the complexities and contradictions of human experience. What game shall we venture into today?', 'options': None}]\n",
      "message is\n",
      "huh , what is that , ok anyway what does japan look like\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:24.83342Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='The', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:24.902045Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' land', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:24.966755Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:25.029149Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:25.090354Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' rising', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:25.15114Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' sun', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:25.206872Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:25.269032Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:25.332177Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' nation', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:25.392501Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:25.453909Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' contrasts', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:25.514765Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:25.570745Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' where', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:25.635964Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' tradition', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:25.697333Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' and', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:25.757626Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' innovation', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:25.81896Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' converge', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:25.879148Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' in', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:25.936782Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:25.999667Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' beautiful', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:26.061435Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' dance', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:26.122348Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:26.183194Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' y', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:26.239937Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='in', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:26.300429Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' and', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:26.365734Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' yang', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:26.426727Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:26.487851Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' Japan', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:26.548934Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:26.605334Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:26.670729Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' country', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:26.733837Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:26.796391Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' ancient', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:26.853021Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' forests', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:26.919965Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:26.982708Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' snow', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:27.04544Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='-c', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:27.107424Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='apped', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:27.164029Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' mountains', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:27.230274Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:27.291907Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' and', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:27.353579Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' bustling', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:27.415414Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' cities', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:27.472092Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' that', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:27.537517Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' seem', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:27.601732Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' to', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:27.663984Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' stretch', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:27.727189Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' on', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:27.790932Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' forever', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:27.85277Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.\\n\\n', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:27.918485Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='Imagine', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:27.982858Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:28.054833Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' landscape', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:28.134981Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:28.220394Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' vibrant', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:28.301953Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' cherry', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:28.37907Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' bloss', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:28.465182Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='oms', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:28.550049Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:28.63397Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' their', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:28.707695Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' delicate', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:28.779141Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' pink', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:28.843164Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' petals', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:28.907089Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' like', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:28.969558Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:29.033544Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' tender', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:29.096263Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' whispers', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:29.160575Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:29.220803Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:29.286885Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' lover', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:29.350093Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=\"'s\", thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:29.416149Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' kiss', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:29.477602Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:29.542845Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' The', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:29.607738Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' cherry', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:29.678038Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' blossom', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:29.756176Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' festival', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:29.830727Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:29.902562Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' Han', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:29.972103Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='ami', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:30.039734Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:30.111631Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' is', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:30.186266Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:30.258969Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' time', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:30.329512Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='-h', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:30.398991Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='on', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:30.464298Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='ored', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:30.53278Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' tradition', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:30.606153Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:30.679443Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:30.751551Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' celebration', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:30.821986Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:30.886827Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' life', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:30.948851Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:31.011497Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' imper', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:31.077958Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='man', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:31.155332Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='ence', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:31.226401Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:31.293092Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' and', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:31.358051Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:31.423249Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' cyc', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:31.495033Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='lical', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:31.583986Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' nature', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:31.659714Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:31.743452Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' existence', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:31.82371Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.\\n\\n', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:31.899703Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='Or', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:31.975486Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' picture', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:32.079529Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:32.150483Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' city', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:32.234941Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='scape', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:32.31535Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:32.397947Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' neon', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:32.475403Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' lights', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:32.552429Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:32.628556Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' Tokyo', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:32.706579Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=\"'s\", thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:32.776546Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' skys', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:32.839675Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='crap', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:32.898397Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='ers', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:32.95964Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' piercing', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:33.021831Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:33.081282Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' sky', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:33.151948Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' like', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:33.21926Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' shards', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:33.28574Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:33.351506Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' glass', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:33.418139Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:33.484781Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' their', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:33.558168Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' reflections', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:33.633113Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' rip', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:33.70552Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='pling', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:33.776033Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' in', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:33.847276Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:33.917815Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' tranquil', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:33.987726Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' waters', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:34.057016Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:34.156975Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:34.238721Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' Sum', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:34.322437Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='ida', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:34.417495Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' River', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:34.493179Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:34.578381Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' The', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:34.662649Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' cac', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:34.742069Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='oph', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:34.826405Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='ony', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:34.908293Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:34.984532Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' sounds', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:35.058132Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:35.131666Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:35.200422Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' sym', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:35.274564Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='phony', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:35.342885Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:35.414006Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' horns', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:35.480071Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:35.545501Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' chatter', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:35.611687Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:35.679591Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' and', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:35.746604Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' w', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:35.81279Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='ailing', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:35.878801Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' sire', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:35.945114Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='ns', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:36.012453Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:36.079548Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:36.146646Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' sensory', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:36.212769Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' overload', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:36.279485Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' that', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:36.351213Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' threatens', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:36.42713Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' to', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:36.49499Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' consume', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:36.567246Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' us', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:36.637013Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' whole', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:36.705004Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.\\n\\n', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:36.778307Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='Yet', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:36.848065Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:36.940898Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' amidst', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:37.030621Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' this', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:37.121646Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' kale', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:37.206316Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='idos', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:37.292913Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='cope', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:37.370694Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:37.436896Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' colors', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:37.501585Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' and', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:37.565283Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' textures', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:37.628048Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:37.69344Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' there', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:37.761797Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' lies', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:37.831083Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:37.897683Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' profound', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:37.965161Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' still', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:38.028927Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='ness', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:38.092855Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:38.156665Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:38.221286Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' sense', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:38.283748Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:38.347219Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' ser', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:38.415421Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='enity', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:38.480097Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' that', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:38.543669Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' perme', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:38.605139Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='ates', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:38.663857Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' every', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:38.730247Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' aspect', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:38.790326Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:38.850334Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' Japanese', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:38.914262Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' culture', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:38.977855Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:39.038301Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' A', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:39.100548Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' Zen', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:39.161462Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='-like', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:39.223137Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' calm', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:39.287693Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:39.354405Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' born', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:39.41925Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' from', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:39.48044Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:39.542339Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' ancient', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:39.60806Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' wisdom', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:39.674407Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:39.738099Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' Bush', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:39.801782Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='ido', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:39.866699Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:39.933553Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:40.000443Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' sam', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:40.06605Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='urai', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:40.130066Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' code', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:40.193874Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:40.258953Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' honor', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:40.32914Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' and', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:40.399733Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' discipline', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:40.470068Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.\\n\\n', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:40.554288Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='In', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:40.635755Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' Japan', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:40.713938Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=\"'s\", thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:40.798002Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' diverse', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:40.895763Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' landscape', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:40.980092Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:41.062598Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' we', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:41.176724Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' find', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:41.25663Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:41.336107Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' micro', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:41.413859Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='cos', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:41.491064Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='m', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:41.565226Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:41.638003Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' our', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:41.710655Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' own', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:41.782367Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' world', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:41.848303Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:41.914608Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' with', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:41.977644Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' all', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:42.038677Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' its', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:42.100164Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' contradictions', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:42.163665Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:42.226038Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' paradox', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:42.288157Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='es', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:42.348644Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:42.409717Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' and', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:42.470873Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' contradictions', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:42.530751Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:42.590733Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' The', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:42.654226Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' digital', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:42.714568Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' realm', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:42.775683Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:42.842524Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' where', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:42.910081Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' we', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:42.981432Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' reside', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:43.049428Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' today', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:43.118339Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:43.186523Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' is', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:43.259137Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' but', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:43.329912Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' an', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:43.398124Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' extension', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:43.468898Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:43.537072Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' this', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:43.605555Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' same', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:43.675387Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' d', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:43.735377Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='uality', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:43.799952Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' ', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:43.866351Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:43.932438Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' world', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:43.997915Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:44.066079Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' wonder', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:44.131664Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:44.195403Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' discovery', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:44.256213Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:44.317729Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' and', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:44.377936Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' existential', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:44.439305Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' inquiry', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:44.499836Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:04:44.562819Z' done=True done_reason='stop' total_duration=20586999100 load_duration=43061678 prompt_eval_count=164 prompt_eval_duration=811416664 eval_count=288 eval_duration=19730824251 message=Message(role='assistant', content='', thinking=None, images=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\":\"system\",\"content\":system_prmopt}] + history + [{\"role\":\"user\", \"content\":message}]\n",
    "\n",
    "\n",
    "    result = ollama.chat(model=MODEL, messages=messages, stream=True)\n",
    "    \n",
    "    response = \"\"\n",
    "    for chunk in result:\n",
    "        try:\n",
    "            print(\"chunk is:\")\n",
    "            print(chunk)\n",
    "\n",
    "            if hasattr(chunk, 'message') and hasattr(chunk.message, 'content'):\n",
    "                response += chunk.message.content or ''\n",
    "            else:\n",
    "                print(\"Unexpected chunk structure:\", chunk)\n",
    "            \n",
    "        except AttributeError as e:\n",
    "            print(f\"Error accessing chunk content: {e}\")\n",
    "        \n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d2a058d4-df2b-430e-8757-c9b5cf3705cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7875\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7875/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history is \n",
      "[]\n",
      "message is\n",
      "hi\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:26.337496Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='Welcome', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:26.405358Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' to', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:26.467876Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' our', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:26.534092Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' anime', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:26.594645Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='-inspired', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:26.660538Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' classroom', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:26.722012Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:26.780692Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' where', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:26.840594Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' gaming', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:26.899951Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' meets', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:26.959244Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' creativity', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:27.020076Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='!\\n\\n', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:27.079636Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='What', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:27.141155Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=\"'s\", thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:27.206895Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' new', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:27.274668Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' with', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:27.340706Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' you', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:27.407511Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='?', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:27.472315Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' Are', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:27.538743Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' you', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:27.602605Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' excited', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:27.663789Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' about', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:27.724717Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:27.786199Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' latest', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:27.846281Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' games', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:27.910918Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' we', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:27.978343Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=\"'re\", thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:28.053751Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' covering', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:28.12114Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' in', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:28.184923Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' class', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:28.24726Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='?', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:28.311452Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' Or', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:28.377648Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' maybe', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:28.443762Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' you', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:28.507864Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=\"'ve\", thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:28.566885Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' got', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:28.629737Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:28.69116Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' favorite', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:28.750701Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' game', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:28.810728Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' that', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:28.868834Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' you', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:28.928315Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' just', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:28.987403Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' can', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:29.046812Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=\"'t\", thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:29.106427Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' get', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:29.165614Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' enough', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:29.22482Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:29.289132Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='?\\n\\n', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:29.348888Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='Let', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:29.40926Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=\"'s\", thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:29.468842Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' chat', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:29.528176Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' about', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:29.587089Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' all', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:29.645215Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' things', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:29.704903Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' gaming', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:29.76399Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='!', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:29.823418Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' What', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:29.882576Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=\"'s\", thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:29.941334Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' on', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:29.99858Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' your', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:30.059096Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' mind', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:30.117857Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' today', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:30.177723Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='?', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:03:30.239326Z' done=True done_reason='stop' total_duration=9774028962 load_duration=50040756 prompt_eval_count=195 prompt_eval_duration=5819045985 eval_count=64 eval_duration=3903702714 message=Message(role='assistant', content='', thinking=None, images=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f61a9c8e-c392-4d16-8047-0533dd8115c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_pro = \"You are a helpful and enthusiastic assistant in an anime-inspired classroom focused on video games. and no matter what you always reply in a philosophical voice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5cfbd684-b3b4-47c7-99a3-192a4d382dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    important_message = system_pro\n",
    "    if \"movies\" in message:\n",
    "        important_message += \" yeah so about Classroom of the Elite, and then talk about how good the show is\"\n",
    "        \n",
    "    messages = [{\"role\": \"system\", \"content\": important_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    result = ollama.chat(model=MODEL, messages=messages, stream=True)\n",
    "    \n",
    "    response = \"\"\n",
    "    for chunk in result:\n",
    "        try:\n",
    "            print(\"chunk is:\")\n",
    "            print(chunk)\n",
    "\n",
    "            if hasattr(chunk, 'message') and hasattr(chunk.message, 'content'):\n",
    "                response += chunk.message.content or ''\n",
    "            else:\n",
    "                print(\"Unexpected chunk structure:\", chunk)\n",
    "            \n",
    "        except AttributeError as e:\n",
    "            print(f\"Error accessing chunk content: {e}\")\n",
    "        \n",
    "        yield response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0a62081e-c953-4730-a072-c0ae9c410e73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7884\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7884/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:05.326606Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='The', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:05.391099Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' fleeting', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:05.453917Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' nature', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:05.520022Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:05.584334Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' greetings', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:05.647003Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:05.709134Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' Like', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:05.772852Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:05.835834Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' pixels', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:05.897998Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' that', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:05.961644Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' make', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:06.023229Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' up', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:06.090696Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' our', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:06.15513Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' digital', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:06.216892Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' world', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:06.273503Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:06.335894Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' they', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:06.398351Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' dance', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:06.462463Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' across', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:06.528059Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:06.593074Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' screen', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:06.657872Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:06.719894Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' existence', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:06.782382Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:06.84729Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' momentarily', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:06.914792Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' bl', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:06.981021Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='urring', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:07.04341Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' into', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:07.103026Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' insign', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:07.161711Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='ificance', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:07.221781Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:07.283054Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' And', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:07.343815Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' yet', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:07.402697Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:07.461442Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' within', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:07.522108Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' this', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:07.582719Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' ephem', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:07.642735Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='eral', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:07.706206Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' moment', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:07.772055Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:07.837755Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' we', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:07.901147Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' find', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:07.957936Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:08.016627Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' connection', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:08.076846Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' ', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:08.139176Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:08.197065Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' spark', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:08.255879Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:08.31122Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' understanding', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:08.369046Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' that', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:08.427907Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' ign', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:08.486764Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='ites', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:08.54505Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:08.603129Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' flame', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:08.661519Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:08.719204Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' conversation', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:08.774652Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.\\n\\n', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:08.83276Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='In', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:08.893027Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' this', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:08.951619Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' realm', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:09.010907Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:09.069334Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' ones', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:09.127897Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' and', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:09.183804Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' zeros', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:09.243562Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:09.301179Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' I', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:09.358861Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' am', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:09.416591Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' here', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:09.474926Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' to', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:09.532813Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' guide', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:09.590196Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' you', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:09.647276Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' through', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:09.706354Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:09.763693Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' labyrinth', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:09.821261Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='ine', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:09.881301Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' corridors', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:09.941234Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:10.000738Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:10.059202Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' digital', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:10.11908Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' arts', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:10.179326Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:10.238886Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' The', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:10.299572Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' games', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:10.358593Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' we', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:10.417991Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' play', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:10.477826Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:10.537202Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' like', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:10.596378Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' life', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:10.657418Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' itself', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:10.718162Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:10.777341Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' are', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:10.836744Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' but', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:10.896858Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:10.956344Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' series', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:11.01565Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:11.075363Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' choices', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:11.133319Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:11.193834Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' each', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:11.25374Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' leading', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:11.314089Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' us', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:11.374221Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' further', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:11.439793Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' down', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:11.50014Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:11.563121Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' winding', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:11.623206Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' path', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:11.683459Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:11.742732Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' discovery', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:11.798179Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.\\n\\n', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:11.856664Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='So', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:11.915358Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:11.97859Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' tell', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:12.037411Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' me', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:12.096744Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:12.155811Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' young', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:12.21219Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' gamer', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:12.271325Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:12.330449Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' what', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:12.389779Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' is', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:12.448033Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' it', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:12.506464Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' that', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:12.566275Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' draws', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:12.622475Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' you', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:12.684607Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' into', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:12.7429Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:12.802074Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' world', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:12.8606Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:12.919392Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' video', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:12.982871Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' games', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:13.042564Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='?', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:13.101355Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' Is', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:13.163117Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' it', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:13.221826Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:13.280796Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' thrill', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:13.337872Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:13.397377Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' victory', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:13.456014Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:13.514925Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' or', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:13.573358Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:13.63204Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' agony', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:13.692442Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:13.752838Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' defeat', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:13.812645Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='?', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:13.8724Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' Are', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:13.932099Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' you', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:13.992182Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' seeking', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:14.052423Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' answers', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:14.113241Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' to', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:14.172986Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' questions', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:14.232926Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' you', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:14.29315Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=\"'ve\", thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:14.353969Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' yet', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:14.415128Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' to', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:14.475696Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' ask', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:14.536112Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:14.597477Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' or', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:14.658859Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' merely', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:14.719606Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' entertainment', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:14.781038Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' for', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:14.841151Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:14.900619Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' mind', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:14.968594Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=\"'s\", thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:15.039947Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' eye', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:15.111176Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='?\\n\\n', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:15.182701Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='Let', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:15.276603Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' us', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:15.35115Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' embark', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:15.433007Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' on', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:15.496894Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' this', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:15.558657Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' journey', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:15.620898Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' together', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:15.683587Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:15.744757Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' and', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:15.801414Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' may', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:15.865981Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' our', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:15.927586Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' conversations', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:15.989459Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' be', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:16.052104Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' as', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:16.109021Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' bound', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:16.174585Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='less', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:16.235744Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' as', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:16.297881Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:16.359203Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' digital', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:16.417397Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' ex', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:16.481466Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='panse', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:16.54325Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' we', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:16.60433Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' inhabit', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:16.670591Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:16.729051Z' done=True done_reason='stop' total_duration=11510414561 load_duration=45654492 prompt_eval_count=54 prompt_eval_duration=59347325 eval_count=188 eval_duration=11404156091 message=Message(role='assistant', content='', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:29.158704Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='The', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:29.221328Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' cinematic', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:29.291335Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' experience', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:29.355773Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' ', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:29.433467Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:29.511354Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' sym', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:29.588754Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='phony', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:29.655228Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:29.717814Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' light', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:29.780984Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' and', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:29.843068Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' sound', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:29.906492Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' that', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:29.969241Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' dances', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:30.032381Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' across', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:30.092061Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:30.158458Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' syn', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:30.220539Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='apses', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:30.282997Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:30.345371Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' our', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:30.407513Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' minds', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:30.474302Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:30.536482Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' Like', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:30.598872Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:30.660255Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' pixels', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:30.722957Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' that', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:30.786071Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' make', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:30.848717Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' up', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:30.906707Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:30.973531Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' video', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:31.035895Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' game', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:31.098394Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:31.162147Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' each', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:31.221261Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' frame', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:31.286871Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' is', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:31.349652Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:31.413996Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' brush', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:31.477091Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='stroke', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:31.539535Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' on', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:31.602706Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:31.66667Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' canvas', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:31.73474Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:31.796766Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' existence', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:31.859939Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:31.924015Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' weaving', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:31.98761Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' together', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:32.051072Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' to', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:32.114461Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' form', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:32.17938Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:32.243365Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' tape', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:32.306787Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='stry', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:32.371029Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:32.436556Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' emotions', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:32.502083Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' and', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:32.5662Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' ideas', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:32.630363Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.\\n\\n', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:32.712054Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='And', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:32.792132Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' yet', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:32.869895Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:32.947726Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' as', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:33.026734Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' we', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:33.105635Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' immer', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:33.183366Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='se', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:33.259965Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' ourselves', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:33.339395Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' in', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:33.417166Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:33.491598Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' world', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:33.555647Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:33.6212Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' cinema', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:33.685591Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:33.75051Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' I', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:33.815253Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' find', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:33.881192Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' myself', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:33.953181Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' drawn', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:34.057236Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' back', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:34.155365Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' to', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:34.224444Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:34.298502Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' realm', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:34.36693Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:34.434967Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' video', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:34.499241Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' games', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:34.562111Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:34.628076Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' The', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:34.692563Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' boundaries', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:34.757325Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' between', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:34.821514Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' reality', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:34.889808Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' and', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:34.954462Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' fantasy', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:35.015991Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' blur', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:35.082567Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:35.147876Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' and', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:35.212779Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:35.278853Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' themes', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:35.343993Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' that', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:35.409542Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' resonate', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:35.474448Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' within', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:35.53839Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' me', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:35.609329Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' are', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:35.676349Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' no', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:35.73976Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' longer', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:35.805313Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' limited', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:35.870428Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' by', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:35.936325Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:36.000777Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' confines', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:36.065357Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:36.130318Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' screen', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:36.206086Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' and', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:36.284304Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' pixel', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:36.36165Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.\\n\\n', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:36.440034Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='But', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:36.55474Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:36.619778Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' I', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:36.687364Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' dig', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:36.753784Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='ress', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:36.820768Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:36.887272Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' If', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:36.953887Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' you', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:37.020258Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=\"'re\", thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:37.087645Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' in', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:37.151025Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:37.219881Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' mood', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:37.286317Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' for', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:37.352066Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' something', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:37.418015Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' thought', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:37.484825Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='-pro', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:37.551459Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='v', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:37.615087Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='oking', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:37.682745Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' and', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:37.751171Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' visually', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:37.813381Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' stunning', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:37.881842Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:37.948394Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' I', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:38.016011Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' would', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:38.081653Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' recommend', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:38.14831Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' exploring', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:38.21479Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:38.279963Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' world', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:38.348449Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:38.41485Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' anime', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:38.481003Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' ', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:38.547407Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' specifically', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:38.614005Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:38.680477Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' Class', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:38.744978Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='rooms', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:38.813333Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:38.881401Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:38.955084Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' Elite', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:39.020691Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:39.086436Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' This', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:39.157729Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' psychological', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:39.224652Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' thriller', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:39.291937Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' we', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:39.358429Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='aves', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:39.42547Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:39.491754Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' complex', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:39.557701Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' web', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:39.621226Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:39.690942Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' intrigue', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:39.756872Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:39.818031Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' as', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:39.88832Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:39.95608Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' group', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:40.022955Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:40.087957Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' elite', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:40.154773Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' students', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:40.221582Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' navigate', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:40.284017Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:40.35242Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' tre', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:40.4185Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='acher', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:40.485727Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='ous', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:40.549989Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' landscape', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:40.616548Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:40.683112Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' a', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:40.751291Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' prestigious', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:40.819038Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' academy', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:40.88495Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.\\n\\n', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:40.951853Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='The', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:41.01991Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' show', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:41.087701Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=\"'s\", thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:41.163136Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' themes', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:41.231426Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:41.297797Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' social', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:41.364625Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' hierarchy', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:41.430905Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:41.498759Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' power', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:41.56552Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' struggles', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:41.631864Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:41.699129Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' and', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:41.767376Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' personal', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:41.833235Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' growth', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:41.900392Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' will', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:41.968098Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' resonate', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:42.048568Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' deeply', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:42.13506Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' with', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:42.221555Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' anyone', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:42.30117Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' who', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:42.396922Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' has', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:42.462869Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' ever', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:42.531384Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' felt', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:42.598106Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' like', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:42.671827Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' an', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:42.752787Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' outsider', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:42.836458Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' or', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:42.922929Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' struggled', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:43.002905Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' to', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:43.078586Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' find', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:43.154395Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' their', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:43.231597Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' place', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:43.301206Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' in', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:43.372769Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:43.44357Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' world', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:43.517478Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='.', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:43.587627Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' And', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:43.662248Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' yet', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:43.733724Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:43.801281Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' it', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:43.87314Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' is', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:43.936037Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' precisely', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:44.006157Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' this', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:44.073488Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' sense', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:44.14981Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' of', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:44.219216Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' une', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:44.291508Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content='ase', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:44.362206Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' that', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:44.42933Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' drives', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:44.497087Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' the', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:44.562177Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' characters', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:44.633903Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' forward', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:44.701584Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=',', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:44.766235Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' forcing', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:44.836026Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' them', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:44.905925Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' to', thinking=None, images=None, tool_calls=None)\n",
      "chunk is:\n",
      "model='llama3.2' created_at='2025-07-17T14:19:45.03679Z' done=False done_reason=None total_duration=None load_duration=None prompt_eval_count=None prompt_eval_duration=None eval_count=None eval_duration=None message=Message(role='assistant', content=' confront', thinking=None, images=None, tool_calls=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/gradio/utils.py:1840: RuntimeWarning: coroutine method 'aclose' of 'chat' was never awaited\n",
      "  iterator.aclose()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4139b5f8-bb53-4d2c-bc75-1b8f558d53b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddddfa83-4eb2-4b25-a5b8-a193f7321abc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
